---
title: "Landscape Ecology with R:A tutorial with raster and sf"
fig_caption: false
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
---

```{r setup, echo=FALSE, warning=FALSE, purl=FALSE, message=FALSE}
library(knitr)
options(repos="http://cran.rstudio.com/")
pkgs <- c("sp","sf", "rgdal", "rgeos", "raster", "dplyr","spatstat","maptools","SDMTools")
x<-lapply(pkgs, library, character.only = TRUE)
opts_chunk$set(tidy=F, root.dir = ".", cach=TRUE)
```

In this tutorial we will introduce the packages required for geospatial work in R, show how to read in a few spatial data types, demonstrate several ways to calculate landscape metrics, and briefly touch on spatial statistics.  It is assumed that you have [R and RStudio installed](https://github.com/rhodyrstats/intro_r_workshop#software) and that you, at a minimum, understand the basic concepts of the R language (e.g. you can work through[R For Cats](https://rforcats.net)).

# Core Spatial Packages

## Required packages (the good old days)
Within in the last several years there has been a lot of effort spent on adding spatial data handling and analysis capability to R.  Thanks to the very significant effort of the package authors we now have the foundation for doing GIS entirely within R. 

The four packages that provide this foundation are:

- [sp](https://cran.r-project.org/web/packages/sp/index.html)
- [rgdal](https://cran.r-project.org/web/packages/rgdal/index.html)
- [raster](https://cran.r-project.org/web/packages/raster/index.html)
- [rgeos](https://cran.r-project.org/web/packages/rgeos/index.html)

Let's dig in a bit deeper on each of these.

### sp
The `sp` package provides the primary spatial data structures for use in R.  Many other packages assume your data is stored as one of the `sp` data structures.  Getting into the details of these is beyond the scope of this workshop, but look at the [introduction to sp vignette for more details](https://cran.r-project.org/web/packages/sp/vignettes/intro_sp.pdf).  That being said, we will be working mostly with `SpatialPointsDataFrame` and `SpatialPolygonsDataFrame`.  More on that later.

Getting `sp` added is no different than adding any other package that is on CRAN.


```{r, eval=FALSE}
install.packages("sp")
library("sp")
```

### rgdal
The `rgdal` package provides tools for reading and writing multiple spatial data formats.  It is based on the [Geospatial Data Abstraction Library (GDAL)](http://www.gdal.org/) which is a project of the Open Source Geospatial Foundation (OSGeo).  The primary use of `rgdal` is to read various spatial data formats into R and store them as `sp` objects.  In this workshop, we will be only using `rgdal` to read in shape files, but it has utility far beyond that.  

As before, nothing special to get set up with `rgdal` on windows.  Simply:


```{r, eval=FALSE}
install.packages("rgdal")
library("rgdal")
```

Getting set up on Linux or Mac requires more effort (i.e. need to have GDAL installed).  

### raster
Although `sp` and `rgdal` provide raster data capabilities, they do require that the full raster dataset be read into memory.  This can have some performance implications as well as limits the size of datasets you can readily work with.  The `raster` package works around this by working with raster data on the disk.  That too has some performance implications, but for the most part, in my opinion anyway, `raster` makes it easier to work with raster data.  It also provides several additional functions for analyzing raster data.  

To install, just do: 


```{r, eval=FALSE}
install.packages("raster")
library("raster")
```

### rgeos
The last of the core packages for doing GIS in R is `rgeos`.  Like `rgdal`, `rgeos` is a project of OSgeo.  It is a wrapper around the [Geometry Engine Open Source](https://trac.osgeo.org/geos/) c++ library and provides a suite of tools for conducting vector GIS analyses.  

To install


```{r, eval=FALSE}
install.packages("rgeos")
library("rgeos")
```

For Linux and Mac the GEOS library will also need to be available.  As with `rgdal` this is a bit beyond the scope of this tutorial.

## Cutting edge: sf

Things are changing quickly in the R/spatial analysis world and the most fundamental change is via the `sf` package.  This package aims to replace `sp`, `rgdal`, and `rgeos`.  There are a lot of reasons why this is a good thing, but that is a bit beyond the scope of this tutorial.  Suffice it to say it should make things faster and simpler!

To install `sf`:

```{r, eval=FALSE}
install.packages("sf")
library("sf")
```


## Exercise 1
The first exercise won't be too thrilling, but we need to make sure everyone has the packages installed. 

1.) Install `sp` and load `sp` into your library.
2.) Repeat, with `sf`,`rgdal`, `raster`, and `rgeos`.

## Interacting with an external GIS
Although we won't be working with external GIS in this tutorial, there are several packages that provide ways to move back and forth from another GIS and R.  For your reference, here are some.

- [spgrass6](https://cran.r-project.org/web/packages/spgrass6/index.html): Provides an interface between R and [GRASS 6+](https://grass.osgeo.org/download/software/#g64x).  Allows for running R from within GRASS as well as running GRASS from within R.  
- [rgrass7](https://cran.r-project.org/web/packages/rgrass7/index.html): Same as `spgrass6`, but for the latest version of GRASS, [GRASS 7](https://grass.osgeo.org/download/software/#g70x).
- [RPyGeo](https://cran.r-project.org/web/packages/RPyGeo/index.html): A wrapper for accessing ArcGIS from R.  Utilizes intermediate python scripts to fire up ArcGIS.  Hasn't been updated in some time.
- [RSAGA](https://cran.r-project.org/web/packages/RSAGA/index.html): R interface to the command line version of [SAGA GIS](http://www.saga-gis.org/en/index.html).

## Spatial analysis packages

There are many packages for doing various types of spatial analysis in R.  For this tutorial we will look at only a few 

### SDMTools

This package is a large suite of tools for species distribution modelling.  As part of that suite, the FRAGSTATS metrics are inlcuded.

### spatstat

This is a huge package and will take care of pretty much all of your point pattern analysis needs.  

### spdep

Also another huge package for spatial analysis.  This one is dense, but has all of your autocorrelation/variogram functions!

## Exercise 2

1. Install and load `SDMTools`, `spatstat`, and `spdep`.

# Reading in spatial data

## sp

Reading in data with `sp` requires `rgdal` which supports many different data formats.  For this quick tutorial lets see an example of reading in a shapefile in the current working directory.

```{r}
rand <- readOGR(".","rand")
plot(rand)
```

## raster
To read in raster datasets we can use the `raster` packages `raster()` function.  For most raster formats it is simply a matter of telling `raster()` to file location.

```{r}
nlcd <- raster("nlcd.tif")
plot(nlcd)
```

## sf
Lastly, reading in data with `sf` is also pretty straightforward.

```{r}
sf_rand <- st_read("rand.shp")
```

One of the benefits of using `sf` is the speed.  In my tests it is about twice as fast.  Let's look at a biggish shape file with 1 million points!

![1 million points](https://media4.giphy.com/media/13B1WmJg7HwjGU/giphy.gif)

```{r}
#The old way
system.time(readOGR(".","big"))

#The sf way
system.time(st_read("big.shp"))
```

## Exercise 3

1. Read in the rest of the example shapefiles with `readOGR()`. These are `unif.shp` and `clumped.shp`.  Name them `unif` and `clumped`, respectively.

# Landscape Metrics

Landscape metrics is a pretty big topic and a HUGE number of metrics can be calculated.  There are of course many ways to do that, but, in my experience, the most common has been to use [FRAGSTATS](http://www.umass.edu/landeco/research/fragstats/fragstats.html), a stand alone program that has seen many iterations since it was first released as a series of `AML` amd `C` (I'm dating myself) tools back in 1994.  A stand-alone R implementation has not been created but most of the metrics have been included in the `SDMTools` package.  Not sure how much active development is going on with `SDMTools` (it was last updated in August of 2014) but the code should be relatively stable.  The primary purpose for `SDMTools` is species distribution modelling, but it does have two functions for caluclating landscape metrics: `PatchStat()` and `ClassStat()`.

Before we get started with those, make sure `SDMTools` is installed and loaded/

```{r eval=FALSE}
install.packages("SDMTools")
library("SDMTools")
```

## Class Metrics

Let's start with the class level landscape metrics.  For this all we need to do is point to the land cover data (it is expecting a raster and supports multiple data structures).

```{r cache=TRUE}
nlcd_class_metrics <- ClassStat(mat = nlcd, cellsize = 30)
dplyr::tbl_df(nlcd_class_metrics)
```

## Patch Metrics
Calculating the patch metrics is a bit more involved becuase it is looking for a binary raster.  So if we want to look at the metrics for all forest patches we need to pull those out of our landcover.  Raster works well with logical statements and will return the cells that match as another raster.  We can string those together with soem "or's" to get all forest patches.  Additionally, we want to get each individual patch labeled.  We can so that with the `SDMTools` function `ConnCompLabel()`.  

```{r, cache = TRUE}
nlcd_forest <- ConnCompLabel(nlcd==41|nlcd==42|nlcd==43)
plot(nlcd_forest)
```

Then to calculate the individual patch metrics.

```{r cache=TRUE}
nlcd_forest_patch_metrics <- PatchStat(mat = nlcd_forest, cellsize = 30)
dplyr::tbl_df(nlcd_forest_patch_metrics)
```

And another example for water.

```{r, cache = TRUE}
nlcd_water <- ConnCompLabel(nlcd==11)
plot(nlcd_water)
```

Then the  metrics.

```{r cache=TRUE}
nlcd_water_patch_metrics <- PatchStat(mat = nlcd_water, cellsize = 30)
dplyr::tbl_df(nlcd_water_patch_metrics)
```

## Roll your own

While there are lots of things included in the `SDMTools` functions there are also many other types of metrics that may not be included.  In that case you might want to roll your own metrics.  At this point, that is beyond the scope of this tutorial.  Check back in the future!

## Exercise 4

1. Calculate patch statistics for the "developed" classes.  The NLCD classes are listed on the [MRLC Website](https://www.mrlc.gov/nlcd11_leg.php).

# Spatial Statistics

The second big section on landscape ecology data analyis relates to spatial statistics.  In this tutorial we will cover [point pattern analysis](#point-pattern-analysis), [autocorrelation and variography](#autocorrelation-and-variography), and [spatial interpolation](#spatial-interpolation)

## Point Pattern Analysis
Point pattern analysis is supported by many packages but the one that seems to have the most complete functionality (based on my VERY limited experience working with point pattern in R) is `spatstat`.  If you are looking for a more complete review of point pattern analysis in R, [the FWS has a good tutorial](https://training.fws.gov/courses/references/tutorials/geospatial/CSP7304/documents/PointPatterTutorial.pdf).

One issue we will need to deal with is that many of the packages for spatial analysis preceeded the formal definitions of spatial data in R (e.g. `sp`, `raster`, and `sf`) thus they have their own data formats.  We will need to manipulate the data that we have read into R and create a `ppp` object.  Below shows examples for the `sp` and `sf` objects.  

First lets convert one of the `sp` objects.  The package `maptools` currently provides many of these conversions via the `as` functions for `sp` objects.

```{r}
library(maptools)
#coordinates(rand) = ~x+y
rand_ppp <- as(rand,"ppp")
plot(rand_ppp)
```

Since `sf` is so new their aren't many of these conversion functions yet available.  We can roll our own and create the `ppp` object.

```{r}
sf_rand_coords <- matrix(unlist(sf_rand$geometry), ncol = 2, byrow = T)
sf_rand_owin <- owin(st_bbox(sf_rand)[c(1,3)],st_bbox(sf_rand)[c(2,4)])
sf_rand_ppp <- ppp(x = sf_rand_coords[,1], y = sf_rand_coords[,2],
                   window = sf_rand_owin, check = T)
plot(sf_rand_ppp)
```

The hardest part of this is to make the conversion of our data structures.  Now that we have the `ppp` object we can start to analyze the data.

### Countour plot

First, some exploratory visualization.  Nice, but I need to think about what this is showing us...

```{r}
contour(density(rand_ppp))
```


### Quadrat count
We can work on a count of points per quadrats

```{r}
rand_qc <- quadratcount(sf_rand_ppp, 3,3)
plot(rand_qc)
plot(sf_rand_ppp, add = T, cex = 0.5, col = "grey")
```

### Ripley's K
And lastly, we can look at the Ripley's K plot as it was presented to us in the [Turner and Gardner book](http://www.springer.com/us/book/9781493927937).

```{r}
rand_pp_k <- Kest(rand_ppp)
plot(rand_pp_k)
```


## Exercise 5

1. Convert the other `sp` objects, `unif` and `clumped`, into `ppp` objects.  
2. Plot out `quadratcount` object for both.  Use a 3X3 quadrat design.
3. Plot the Ripley's K estimates for both objects as well.

## Autocorrelation and Variography

### Moran's I - Testing Residuals

```{r}
#From the spdeb help
library(spdep)
data(oldcol)
oldcrime.lm <- lm(CRIME ~ HOVAL + INC, data = COL.OLD)
lm.morantest(oldcrime.lm,nb2listw(COL.nb, style = "W"))
```

### Moran's I for a raster

Moran(nlcd)

### Variogram

## Spatial Interpolation

### Inverse Distance Weighting

### Splines

### Kriging






